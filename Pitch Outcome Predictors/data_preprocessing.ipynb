{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97c2100a",
   "metadata": {},
   "source": [
    "In this notebook we preprocess baseball data into time series data, which we export to multi-class classification models predicting the pitch outcome of a given pitcher, called events in pybaseball. We do a train-test split with validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161e8550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pybaseball\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# Enable cache because importing pybaseball is a large query\n",
    "pybaseball.cache.enable()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a444543",
   "metadata": {},
   "source": [
    "We consider consecutive sequences of pitches of length pitch_sequence_length. Our objective is to predict the last pitch outcome in the sequence using the previous pitch_sequence_length-1 pitches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2991a01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_sequence_length=5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94622c6",
   "metadata": {},
   "source": [
    "Upload the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7af53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_start = '2023-05-01'\n",
    "train_end = '2023-07-01'\n",
    "\n",
    "val_start = '2024-05-01'\n",
    "val_end = '2024-05-05'\n",
    "\n",
    "test_start = '2025-05-01'\n",
    "test_end = '2025-05-05'\n",
    "\n",
    "# Train-test split with validation\n",
    "train_data = pybaseball.statcast(start_dt=train_start, end_dt=train_end, verbose=True)\n",
    "val_data = pybaseball.statcast(start_dt=val_start, end_dt=val_end, verbose=True)\n",
    "test_data = pybaseball.statcast(start_dt=test_start, end_dt=test_end, verbose=True)\n",
    "\n",
    "print(len(train_data), len(val_data), len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7564824a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any possible duplicate rows\n",
    "train_data = train_data.drop_duplicates()\n",
    "val_data = val_data.drop_duplicates()\n",
    "test_data = test_data.drop_duplicates()\n",
    "\n",
    "print(len(train_data), len(val_data), len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2fe96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Size of all data:', len(train_data) + len(val_data) + len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bef9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New pitch data row is added to the top of the dataframe. Here we see this for a specific pitcher.\n",
    "specific_pitcher_data = train_data[train_data['pitcher'].isin([605447])].copy()\n",
    "print('Data for pitcher with ID 605447')\n",
    "print(specific_pitcher_data[['pitcher', 'game_date', 'at_bat_number', 'pitch_number']].head(20))\n",
    "\n",
    "# Sort the pitching data in increasing time order by reversing the order of the rows\n",
    "print('Sorted pitch data')\n",
    "sorted_specific_pitcher_data = specific_pitcher_data[::-1]\n",
    "print(sorted_specific_pitcher_data[['pitcher', 'game_date', 'at_bat_number', 'pitch_number']].head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82794784",
   "metadata": {},
   "source": [
    "Order the rows by increasing time and add pitch count feature to train, validation, test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d725c65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder the rows of pitching data by increasing time\n",
    "train_data = train_data[::-1]\n",
    "val_data = val_data[::-1]\n",
    "test_data = test_data[::-1]\n",
    "\n",
    "# Pitch count (or cumulative pitch number) of any pitch within a game\n",
    "train_data.loc[:, 'pitch_count'] = train_data.groupby(['game_pk', 'pitcher']).cumcount() + 1\n",
    "val_data.loc[:, 'pitch_count'] = val_data.groupby(['game_pk', 'pitcher']).cumcount() + 1\n",
    "test_data.loc[:, 'pitch_count'] = test_data.groupby(['game_pk', 'pitcher']).cumcount() + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46849fe7",
   "metadata": {},
   "source": [
    "Define the set of relevant features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39f2827",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = [\n",
    "    'events',\n",
    "    'pitcher',\n",
    "    'batter',\n",
    "    'pitch_type'\n",
    "]\n",
    "\n",
    "sorting_features = ['game_date', 'at_bat_number', 'pitch_number']\n",
    "\n",
    "counting_features = [\n",
    "    'pitch_count',\n",
    "    'inning',\n",
    "    'balls', 'strikes',\n",
    "    'home_score', 'away_score', 'bat_score', 'fld_score',\n",
    "    'post_home_score', 'post_away_score', 'post_bat_score'\n",
    "]\n",
    "\n",
    "continuous_features = [\n",
    "    'release_speed',\n",
    "    'release_pos_x',\n",
    "    'release_pos_z',\n",
    "    'vx0', 'vy0', 'vz0',\n",
    "    'ax', 'ay', 'az',\n",
    "    'effective_speed'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6714080",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Categorical features')\n",
    "print(train_data[categorical_features].head())\n",
    "\n",
    "print('Sorting features')\n",
    "print(train_data[sorting_features].head())\n",
    "\n",
    "print('Counting features')\n",
    "print(train_data[counting_features].head()) # the backslash \\ in the printed data frame indicates the table is continued in the next line\n",
    "\n",
    "print('Continuous features')\n",
    "print(train_data[continuous_features].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7caeaf02",
   "metadata": {},
   "source": [
    "Clean the training, validation, and testing data by removing columns which are deprecated or have no relation with pitch outcome, followed by removing rows which contain nan values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ed073e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaner(data):\n",
    "    # Only keep games occuring in the R=Regular Season, F=wild card, L=League Championship Series, W=World Series\n",
    "    data = data[data['game_type'].isin(['R', 'F', 'L', 'W'])].copy()\n",
    "\n",
    "    # Keep only relevant features\n",
    "    relevant_data=data.loc[:, categorical_features + sorting_features + counting_features + continuous_features]\n",
    "\n",
    "    # Remove rows with any nan or None values\n",
    "    clean_data = relevant_data.dropna().copy()\n",
    "    \n",
    "    # Below we set the appropriate data types for each column of the DataFrame data. \n",
    "    # Keep in mind that pandas still stores these data types as objects, \n",
    "    # so when we convert to arrays we need to explicitly set their data types again\n",
    "    \n",
    "    # Change all categorical features to string to put them on uniform footing\n",
    "    clean_data.loc[:, categorical_features] = clean_data[categorical_features].astype(str)\n",
    "\n",
    "    # Make sure continuous features are float32\n",
    "    clean_data.loc[:, continuous_features] = clean_data[continuous_features].astype('float32')\n",
    "    \n",
    "    # Change count features to float32 to put them on the same footing as continuous features\n",
    "    clean_data.loc[:, counting_features] = clean_data[counting_features].astype('float32')\n",
    "    \n",
    "    return(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01903057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean train, validation, and test\n",
    "clean_train = data_cleaner(train_data)\n",
    "clean_val = data_cleaner(val_data)\n",
    "clean_test = data_cleaner(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b142054",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clean_train.shape, clean_val.shape, clean_test.shape)\n",
    "print(clean_train[categorical_features].values.dtype)\n",
    "print(clean_train[continuous_features].values.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86dd6ee",
   "metadata": {},
   "source": [
    "Plot relative frequencies of each pitch outcome in training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e2bbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_freq = clean_train['events'].value_counts() / len(clean_train)\n",
    "\n",
    "threshold = 0.001\n",
    "# Filter out relative frequencies below the threshold\n",
    "filtered_rel_freq = rel_freq[rel_freq >= threshold] \n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.barplot(x=filtered_rel_freq.index, y=filtered_rel_freq.values)\n",
    "plt.title('Relative frequencies of pitch outcomes in training data')\n",
    "plt.xlabel('Pitch outcomes')\n",
    "plt.ylabel('Relative frequencies')\n",
    "plt.xticks(rotation=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a28b6f",
   "metadata": {},
   "source": [
    "Filter out rare pitch outcomes from training, validation, and testing data, and make sure that these three data sets cover all remaining pitch outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97652c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set pitch outcomes we will work with\n",
    "pitch_outcomes = [\n",
    "    'field_out',\n",
    "    'strikeout',\n",
    "    'single',\n",
    "    'walk',\n",
    "    'double',\n",
    "    'home_run',\n",
    "    'force_out',\n",
    "    'grounded_into_double_play',\n",
    "    'hit_by_pitch',\n",
    "    'sac_fly',\n",
    "    'triple'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b859f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure training, validation, and testing data contain all possible pitch outcomes before filtering\n",
    "print(\n",
    "    set(pitch_outcomes) <= set(clean_train['events'].unique()),\n",
    "    set(pitch_outcomes) <= set(clean_val['events'].unique()),\n",
    "    set(pitch_outcomes) <= set(clean_test['events'].unique())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27aa4cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out events not contained in pitch_outcomes\n",
    "filtered_clean_train = clean_train[clean_train['events'].isin(pitch_outcomes)].copy()\n",
    "filtered_clean_val = clean_val[clean_val['events'].isin(pitch_outcomes)].copy()\n",
    "filtered_clean_test = clean_test[clean_test['events'].isin(pitch_outcomes)].copy()\n",
    "\n",
    "print(filtered_clean_train.shape, filtered_clean_val.shape, filtered_clean_test.shape)\n",
    "\n",
    "# Label encode categorical features\n",
    "label_encoders = {} # Dictionary of label encoders for each categorical feature\n",
    "for cat_feature in categorical_features:\n",
    "    all_labels = pd.concat([filtered_clean_train[cat_feature], filtered_clean_val[cat_feature], filtered_clean_test[cat_feature]], axis=0)\n",
    "    \n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder.fit(all_labels)\n",
    "    label_encoders[cat_feature] = label_encoder\n",
    "\n",
    "    filtered_clean_train[cat_feature] = label_encoder.transform(filtered_clean_train[cat_feature])\n",
    "    filtered_clean_val[cat_feature] = label_encoder.transform(filtered_clean_val[cat_feature])\n",
    "    filtered_clean_test[cat_feature] = label_encoder.transform(filtered_clean_test[cat_feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4a9c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(label_encoders['events'].classes_)\n",
    "print(len(pitch_outcomes))\n",
    "print(filtered_clean_train['events'].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2493c0",
   "metadata": {},
   "source": [
    "Standardize the continuous features using mean and standard deviation of training features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c168f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute mean and standard deviation of each feature, i.e. column) in train\n",
    "train_standard_scaler = StandardScaler()\n",
    "std_train = filtered_clean_train.copy()\n",
    "\n",
    "# Standardize train using mean and standard deviation of train features\n",
    "std_train[continuous_features] = train_standard_scaler.fit_transform(filtered_clean_train[continuous_features])\n",
    "\n",
    "# Standardize validation using mean and standard deviation of train features\n",
    "std_val = filtered_clean_val.copy()\n",
    "std_val[continuous_features] = train_standard_scaler.fit_transform(filtered_clean_val[continuous_features])\n",
    "\n",
    "# Standardize test using mean and standard deviation of train features\n",
    "std_test = filtered_clean_test.copy()\n",
    "std_test[continuous_features] = train_standard_scaler.transform(filtered_clean_test[continuous_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c10467",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(std_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd13bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(std_train.shape, std_val.shape, std_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb40a506",
   "metadata": {},
   "source": [
    "Obtain the collection of all sliding window sequences of pitches per pitcher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd991bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input std_data is a DataFrame of shape (number of pitches, 28 features)\n",
    "# Output is 3D array of shape (number of windows per pitcher, window size, input size=28 - 3 features)\n",
    "def pitch_sequences(std_data, window_size):\n",
    "# Group the data by pitchers\n",
    "    groups = std_data.groupby('pitcher')\n",
    "\n",
    "    # Create sliding windows of pitches per pitcher\n",
    "    pitch_sequence_list=[]\n",
    "    for _, group in groups:\n",
    "        # Sort pitches (note that sort_values by default is ascending sorting order, i.e. lexicographic)\n",
    "        group = group.sort_values(by=sorting_features)\n",
    "        \n",
    "        # Remove sorting features since their only purpose is for creating sliding windows\n",
    "        group = group.drop(columns=sorting_features) \n",
    "                \n",
    "        for i in range(len(group) - window_size + 1):\n",
    "            window = group.iloc[i:i + window_size]\n",
    "            pitch_sequence_list.append(window.values)\n",
    "            \n",
    "    pitch_sequences = np.stack(pitch_sequence_list, axis=0)\n",
    "    return(pitch_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adab109",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pitch_sequences=pitch_sequences(std_train, pitch_sequence_length)\n",
    "val_pitch_sequences=pitch_sequences(std_val, pitch_sequence_length)\n",
    "test_pitch_sequences=pitch_sequences(std_test, pitch_sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0e83fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_pitch_sequences.shape)\n",
    "print(val_pitch_sequences.shape)\n",
    "print(test_pitch_sequences.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29809f11",
   "metadata": {},
   "source": [
    "Extract labels and setup for model training and testing. All pairs (X,y) below have the following shape: X has shape (number of sequences, pitch_sequence_length-1, input_size=num_features=25) and y has shape (number of sequences,)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e2e9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training, validation, and testing arrays\n",
    "X_train = train_pitch_sequences[:, :-1, :].astype('float32') # Remove the last pitch sequence\n",
    "y_train = train_pitch_sequences[:, -1, 0].astype(int) # For every pitch sequence, take the event of the last pitch data\n",
    "\n",
    "X_val = val_pitch_sequences[:, :-1, :].astype('float32')\n",
    "y_val = val_pitch_sequences[:, -1, 0].astype(int)\n",
    "\n",
    "X_test = test_pitch_sequences[:, :-1, :].astype('float32')\n",
    "y_test = test_pitch_sequences[:, -1, 0].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a3e35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f144998",
   "metadata": {},
   "source": [
    "Export data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258171cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('X_train.npy', X_train)\n",
    "np.save('y_train.npy', y_train)\n",
    "\n",
    "np.save('X_val.npy', X_val)\n",
    "np.save('y_val.npy', y_val)\n",
    "\n",
    "np.save('X_test.npy', X_test)\n",
    "np.save('y_test.npy', y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sports",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
